{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = ['Florida', 'Georgia', 'Delaware',\n",
    "              'Maryland', 'Pennsylvania', 'Ohio',\n",
    "              'Missouri', 'Louisiana', 'California',\n",
    "              'Kansas', 'Indiana', 'New Jersey',\n",
    "              'Alaska', 'Colorado', 'Tennessee',\n",
    "              'District of Columbia', 'Connecticut',\n",
    "              'Illinois', 'Montana', 'Mississippi',\n",
    "              'Nevada', 'North Carolina', 'Massachusetts',\n",
    "              'South Carolina', 'Texas', 'Virginia',\n",
    "              'New York', 'Utah', 'Michigan',\n",
    "              'Maine', 'Arkansas', 'Oklahoma',\n",
    "              'Alabama', 'Nebraska', 'Arizona',\n",
    "              'Oregon', 'New Mexico', 'Iowa',\n",
    "              'New Hampshire', 'Minnesota', 'Kentucky',\n",
    "              'West Virginia', 'Wisconsin', 'Washington',\n",
    "              'North Dakota', 'Rhode Island', 'Idaho',\n",
    "              'South Dakota', 'Hawaii', 'Vermont', 'Wyoming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlieyaris/.venvs/lpthw/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3044: DtypeWarning: Columns (0,5,6,11,13,14,25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../Data Sources/gun_violence_archive_scraped_full.csv')\n",
    "df = df[(df['state'].isnull()==False)].reset_index()\n",
    "df.drop('index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60548"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('../Data Sources/gun_violence_archive_raw_html_scraped.csv').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove pages that have been removed since scraped for a second time.\n",
    "# these have been added back as new pages\n",
    "remove_list = raw_df[raw_df['page_response_code']==404]['incident_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60548"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = deepcopy(df[([s not in remove_list for s in df['incident_id']])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60548"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_html_list = list(set(df[df['city_or_county']=='N.W. PMB #126<br />\\\\nWashington']['incident_id'].astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646\n",
      "646\n"
     ]
    }
   ],
   "source": [
    "print(len(set(list(raw_df['incident_id']))))\n",
    "print(len(raw_html_list))\n",
    "\n",
    "assert len(set(list(raw_df['incident_id'])))==len(raw_html_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, raw_html_id in enumerate(raw_df['incident_id']):\n",
    "    page_id_dic = {}\n",
    "    if \"Geolocation\" in str(raw_df.loc[i, 'raw_html']):\n",
    "        try:\n",
    "            page_id_dic['state'] = str(str(str(raw_df.loc[i, 'raw_html']).split('Geolocation:')[0]).split('</span>')[-2]).split(', ')[1]\n",
    "        except:\n",
    "            page_id_dic['state'] = None\n",
    "        try:\n",
    "            page_id_dic['city_or_county'] = str(str(str(str(raw_df.loc[i, 'raw_html']).split('Geolocation:')[0]).split('</span>')[-2]).split(', ')[0]).split('<span>')[1]\n",
    "        except:\n",
    "            page_id_dic['city_or_county'] = None\n",
    "        try:\n",
    "            page_id_dic['address'] = str(str(str(raw_df.loc[i, 'raw_html']).split('Geolocation:')[0]).split('</span>')[-3]).split('<span>')[-1]\n",
    "        except:\n",
    "            page_id_dic['address'] = None\n",
    "        try:\n",
    "            page_id_dic['latitude'] = str(str(raw_df.loc[i, 'raw_html']).split('Geolocation: ')[1]).split(',')[0]\n",
    "        except:\n",
    "            page_id_dic['latitude'] = None\n",
    "        try:\n",
    "            page_id_dic['longitude'] = str(str(str(raw_df.loc[i, 'raw_html']).split('Geolocation: ')[1]).split(', ')[1]).split('</span>')[0]\n",
    "        except:\n",
    "            page_id_dic['longitude'] = None\n",
    "        possible_location_description = str(str(str(raw_df.loc[i, 'raw_html']).split('Geolocation:')[0]).split('</span>')[-4]).split('<span>')[-1]\n",
    "        if possible_location_description != 'Incident':\n",
    "            page_id_dic['location_description'] = possible_location_description\n",
    "        else:\n",
    "            page_id_dic['location_description'] = None\n",
    "    else:\n",
    "        try:\n",
    "            page_id_dic['state'] = str(str(raw_df.loc[i, 'raw_html']).split('</span><br>\\\\n</div>\\\\n<div>\\\\n<h2>')[1]).split(', ')[-1]\n",
    "        except:\n",
    "            page_id_dic['state'] = None\n",
    "        try:\n",
    "            page_id_dic['city_or_county'] = str(str(str(raw_df.loc[i, 'raw_html']).split('</span><br>\\\\n</div>\\\\n<div>\\\\n<h2>')[1]).split(', ')[-2]).split('<span>')[-1]\n",
    "        except:\n",
    "            page_id_dic['city_or_county'] = None\n",
    "        try:\n",
    "            page_id_dic['address'] = str(str(str(str(raw_df.loc[i, 'raw_html']).split('</span><br>\\\\n</div>\\\\n<div>\\\\n<h2>')[1]).split(', ')[-2]).split('<span>')[-2]).split('</span>')[0]\n",
    "        except:\n",
    "            page_id_dic['address'] = None\n",
    "        page_id_dic['latitude'] = None\n",
    "        page_id_dic['longitude'] = None\n",
    "        page_id_dic['location_description'] = None\n",
    "    try:\n",
    "        page_id_dic['congressional_district'] = str(str(raw_df.loc[i, 'raw_html']).split('Congressional District: ')[1]).split('<br>')[0]\n",
    "    except:\n",
    "        page_id_dic['congressional_district'] = None\n",
    "    try:\n",
    "        page_id_dic['state_house_district'] = str(str(raw_df.loc[i, 'raw_html']).split('State House District: ')[1]).split('<br>')[0]\n",
    "    except:\n",
    "        page_id_dic['state_house_district'] = None\n",
    "    try:\n",
    "        page_id_dic['state_senate_district'] = str(str(raw_df.loc[i, 'raw_html']).split('State Senate District: ')[1]).split('<br>')[0]\n",
    "    except:\n",
    "        page_id_dic['state_senate_district'] = None\n",
    "        \n",
    "    if page_id_dic['city_or_county']=='N.W. PMB #126<br />\\\\nWashington':\n",
    "        try:\n",
    "            page_id_dic['state'] = str(str(raw_df.loc[i, 'raw_html']).split('</span><br>\\\\n</div>\\\\n<div>\\\\n<h2>')[0]).split(', ')[-1]\n",
    "        except:\n",
    "            page_id_dic['state'] = None\n",
    "        try:\n",
    "            page_id_dic['city_or_county'] = str(str(str(raw_df.loc[i, 'raw_html']).split('</span><br>\\\\n</div>\\\\n<div>\\\\n<h2>')[0]).split(', ')[-2]).split('<span>')[-1]\n",
    "        except:\n",
    "            page_id_dic['city_or_county'] = None\n",
    "        try:\n",
    "            page_id_dic['address'] = str(str(str(str(raw_df.loc[i, 'raw_html']).split('</span><br>\\\\n</div>\\\\n<div>\\\\n<h2>')[0]).split(', ')[-2]).split('<span>')[-2]).split('</span>')[0]\n",
    "        except:\n",
    "            page_id_dic['address'] = None\n",
    "        possible_location_description = str(str(str(raw_df.loc[i, 'raw_html']).split('<div class=\"region region-content\">\\\\n<div id=\"block-system-main\" class=\"block block-system\">\\\\n<h1>')[1]).split('<span>')[1]).split('</span>')[0]\n",
    "        if possible_location_description != page_id_dic['address']:\n",
    "            page_id_dic['location_description'] = possible_location_description\n",
    "        else:\n",
    "            page_id_dic['location_description'] = None\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#     print(i, raw_html_id)\n",
    "#     print(page_id_dic)\n",
    "\n",
    "    for key in page_id_dic.keys():\n",
    "        df.loc[df['incident_id']==raw_html_id, key] = page_id_dic[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['incident_id']==1276620) | (df['incident_id']==1299326), 'city_or_county'] = 'Branch (county)'\n",
    "df.loc[(df['incident_id']==1276620) | (df['incident_id']==1299326), 'state'] = 'Michigan'\n",
    "df.loc[df['incident_id']==1189222, 'city_or_county'] = 'Smith (county)'\n",
    "df.loc[df['incident_id']==1189222, 'state'] = 'Mississippi'\n",
    "df.loc[df['incident_id']==1320972, 'city_or_county'] = 'Union (county)'\n",
    "df.loc[df['incident_id']==1320972, 'state'] = 'Illinois'\n",
    "df.loc[df['incident_id']==1197483, 'city_or_county'] = 'Franklin (county)'\n",
    "df.loc[df['incident_id']==1197483, 'state'] = 'Alabama'\n",
    "df.loc[df['incident_id']==1185220, 'city_or_county'] = 'Charlotte'\n",
    "df.loc[df['incident_id']==1185220, 'state'] = 'North Carolina'\n",
    "df.loc[df['incident_id']==1370810, 'state'] = 'Missouri'\n",
    "df.loc[df['incident_id']==1372453, 'state'] = 'Virginia'\n",
    "df.loc[df['incident_id']==1359780, 'state'] = 'Texas'\n",
    "df.loc[df['incident_id']==1365397, 'address'] = 'Gayosa Ave'\n",
    "df.loc[df['incident_id']==1365397, 'city_or_county'] = 'Natchez'\n",
    "df.loc[df['incident_id']==1365397, 'state'] = 'Mississippi'\n",
    "df.loc[df['incident_id']==1365397, 'latitude'] = 31.5638\n",
    "df.loc[df['incident_id']==1365397, 'longitude'] = -91.3818\n",
    "df.loc[df['incident_id']==1365397, 'state_house_district'] = '94'\n",
    "df.loc[df['incident_id']==1365397, 'state_senate_district'] = '38'\n",
    "df.loc[df['incident_id']==1365397, 'congressional_district'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60548 pages before removing 404's.\n",
      "60540 pages before removing 404's.\n"
     ]
    }
   ],
   "source": [
    "# list of pages that became 404's before they could be fixed.\n",
    "# all are presumably added back later by GVA under different IDs\n",
    "not_found_list = [1375727, 1372647, 1348322, 1362719, 1343340, 1333872, 1365099, 1374036]\n",
    "print(\"{} pages before removing 404's.\".format(len(df)))\n",
    "df = deepcopy(df[([s not in not_found_list for s in df['incident_id']])]).reset_index(drop=True)\n",
    "print(\"{} pages before removing 404's.\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pages fixed.\n",
      "New scraper file exported.\n"
     ]
    }
   ],
   "source": [
    "num_pages = len(df[([s not in state_list for s in df['state']])])\n",
    "\n",
    "if num_pages==0:\n",
    "    print(\"All pages fixed.\")\n",
    "    print(\"New scraper file exported.\")\n",
    "    df.to_csv('../Data Sources/gun_violence_archive_scraped_full_2.csv')\n",
    "else:\n",
    "    print(list(df[([s not in state_list for s in df['state']])]['incident_id'].astype(int)))\n",
    "    print(\"\\n\" + str(num_pages) + \" pages still need to be fixed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
