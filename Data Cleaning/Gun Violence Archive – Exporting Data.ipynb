{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import glob\n",
    "import re\n",
    "import requests\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format possible incident id directory into a list\n",
    "incident_file_list = [filename.split('incident/')[1] for filename in glob.glob('../gun_violence_archive_spider/www.gunviolencearchive.org/incident/*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format all possible_ids from std_out file into a list\n",
    "df = pd.read_csv('../Data Sources/std_out.csv', encoding='latin-1', engine='python', index_col='Unnamed: 0')\n",
    "df.columns = ['std_out']\n",
    "incident_std_list = list(df[(['gunviolencearchive.org/incident/' in s for s in df['std_out']])]['std_out'])\n",
    "incident_std_list = [i.split('/incident/')[1] for i in incident_std_list]\n",
    "incident_std_list = [i.split('\\x90')[0] for i in incident_std_list]\n",
    "incident_std_list = [re.sub('[^0-9]','', i) for i in incident_std_list]\n",
    "incident_std_list = list(set(incident_std_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format all ids that have already been catalogued by pandas into a list\n",
    "df = pd.read_pickle('../Pickles/df1.pkl')\n",
    "logged_ids_list = sorted(list(df['incident_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure every catalogued (scraped and downloaded) ID is in the incident folder,\n",
    "# so when requests are made it will only be for non-catalogued IDs\n",
    "check_list = logged_ids_list + incident_std_list\n",
    "check_list = set(list(check_list))\n",
    "add_list = []\n",
    "for incident_id in check_list:\n",
    "    if '/' in str(incident_id):\n",
    "        incident_id = incident_id.split('/')[0]\n",
    "    if str(incident_id) in incident_file_list:\n",
    "        pass\n",
    "    else:\n",
    "        add_list.append(int(incident_id))\n",
    "\n",
    "with open('../gun_violence_archive_spider/www.gunviolencearchive.org/incident/id_add_list.txt', 'w') as f:\n",
    "    for item in add_list:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "print(len(add_list))\n",
    "\n",
    "# command to create list of files from id_add_list.txt\n",
    "# head to the incident directory and then run the following command\n",
    "# cat id_add_list.txt | xargs touch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun creation of list because new items may have been added\n",
    "# format possible incident id directory into a list\n",
    "# catalogue all possible incident_ids into a csv file\n",
    "incident_file_list = [filename.split('incident/')[1] for filename in glob.glob('../gun_violence_archive_spider/www.gunviolencearchive.org/incident/*')]\n",
    "df = pd.DataFrame(incident_file_list, columns = ['possible_incident_ids.csv'])\n",
    "df.to_csv('../Data Sources/possible_incident_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun creation of list because new items may have been added\n",
    "# format all ids that have already been catalogued by pandas into a list\n",
    "df = pd.read_pickle('../Pickles/df1.pkl')\n",
    "logged_ids_list = sorted(list(df['incident_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range from lowest actual id to highest actual id\n",
    "# lets check for ids that may have been missed when scraping ids\n",
    "# these are all possible numbers from smallest id to largest id\n",
    "# if the possible id is not in the possible_incident_id list\n",
    "# known_possible_ids is all ids that have been logged or recorded so far\n",
    "known_possible_ids = incident_file_list + logged_ids_list\n",
    "known_possible_ids = list(set(known_possible_ids))\n",
    "# check for what's already been added to the text file previously\n",
    "already_appended_df = pd.read_csv('../Data Sources/brute_force_id_status_codes.txt')\n",
    "already_appended_df.columns=['id', 'status_code']\n",
    "already_appended_df['id'] = already_appended_df['id'].astype(int)\n",
    "already_appended_df['status_code'] = already_appended_df['status_code'].astype(int)\n",
    "already_appended_list = list(already_appended_df['id'].unique())\n",
    "\n",
    "for possible_id in np.arange(478855, 1350888+1):\n",
    "    if str(possible_id) in known_possible_ids:\n",
    "        pass\n",
    "    elif possible_id in already_appended_list and already_appended_df.loc[already_appended_df['id']==possible_id, 'status_code'].values[0]!=404 and already_appended_df.loc[already_appended_df['id']==possible_id, 'status_code'].values[0]!=200:\n",
    "        pass\n",
    "    else:\n",
    "        with open('../Data Sources/brute_force_id_status_codes.txt', 'a+') as f:\n",
    "            result = requests.get(\"https://www.gunviolencearchive.org/incident/\" + str(possible_id))\n",
    "            f.write(\"\\n\" + str(possible_id) + ', ' + str(result.status_code))\n",
    "            print(str(possible_id) + ', ' + str(result.status_code))\n",
    "            time.sleep(2.5 + random.uniform(0.5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating over ids in incident folder\n",
    "# if it's not in the dataframe, then adding it to the scraper queue\n",
    "id_scrape_list = []\n",
    "for incident_id in incident_file_list:\n",
    "    if '/' in incident_id:\n",
    "        incident_id = incident_id.split('/')[0]\n",
    "    if incident_id=='id_add_list.txt':\n",
    "        pass\n",
    "    elif int(incident_id) in logged_ids_list:\n",
    "        pass\n",
    "    else:\n",
    "        id_scrape_list.append(int(incident_id))\n",
    "\n",
    "with open('../Pickles/incident_id_scrape_queue.pkl', 'wb') as f:\n",
    "    pkl.dump(id_scrape_list, f)\n",
    "    \n",
    "print(len(id_scrape_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting df_date un_scaled data to assets repository for d3.js visualization\n",
    "df_date = pd.read_pickle('../Pickles/df_date_2.pkl')\n",
    "df_date = df_date[['date', 'num_victims']]\n",
    "df_date.to_csv('../../cyaris.github.io/assets/line_graph_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
